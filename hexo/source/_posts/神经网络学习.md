---
title: 神经网络学习
date: 2018-02-08 11:08:47
tags: 
	 - MLP
	 - 深度学习
---



 - &emsp;&emsp;最近几个月一直在看NLP相关的资料，各种算法什么的（基本上看不懂），还好网上一堆大大有做好的工具，还顺带训练好了模型。尝试了大量的分词工具，逐渐明白一些简单的道理，其实好多东西都不要太多数理知识就可以用，本来程序的实现也是为了这么一个目标吧大概。但是初次接触tensorflow和pytorch等工具还是有种回到单片机时代一样，每踩一步都认真查资料。也因此感觉对于代码的理解和操控有了更强一点的概念。


### MorvanZhou的教程
****
 - 可以说这是我最近最大的一个发现了，能用浅显易懂的中文进行深度学习的开课，还是全免费的。目前还只是看了pytorch的几个初级教程，虽然没有说十分理解，但是也在我脑子里有了挺大的一块进展。
 
 - 怎么就说是很大的进展呢，之前一直都没搞懂隐藏层(Hidden Layer)的意义，以及反向传递(backward)有什么意义，昨天看了几遍简单的课程，竟然理解了，比知乎上抛知识，甩公式的解说好太多，因此，强烈安利一波。
 
 - [莫烦老师的系列教程地址][1]
 
 
 
 ### 知识记录
 ****
 
 - **隐藏层**：所谓隐藏层就是除了输入和输出以外的中间层，作用就是拿来作为神经元的容器，一般一层就够了，神经元数量的设计更为重要。
 
 - **神经元**：所谓的神经元也很好理解，就是拿来感知数据的单元，等于每个单元控制一片线性区域，围在一起就是一整个隐藏层。
 
 - **反向传递**：反向传递其实就是一个通过比较训练值和真实值之间产生的误差，自动进行校正操作的过程，神经网络之所以能自主学习也是因为这样。
 
 - **激活函数**：激活函数目的是为了让数据更加线性化，还有可以控制数值的区域，可以说是一种魔法操作。
 
 
 
 [1]: https://morvanzhou.github.io
